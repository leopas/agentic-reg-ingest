<!-- SPDX-License-Identifier: MIT | (c) 2025 Leopoldo Carvalho Correia de Lima -->

# üöÄ Vector Push Guide

Guia completo para enviar chunks ao Qdrant VectorDB com embeddings.

## üìã Overview

O endpoint `/vector/push` permite enviar chunks processados para o Qdrant, gerando embeddings e fazendo upsert idempotente.

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

Adicione ao seu `.env`:

```bash
# Embeddings Configuration
EMBED_PROVIDER=openai              # Options: openai, azure, local
OPENAI_API_KEY=sk-...              # Your OpenAI API key
OPENAI_BASE_URL=                   # Optional: for LM Studio/Ollama (e.g., http://localhost:1234/v1)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
EMBED_DIM=1536                     # Must match model: ada-002=1536, 3-small=1536, 3-large=3072

# Qdrant Vector Database
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=                    # Optional: leave empty for local Qdrant
```

### Modelos Suportados

| Modelo | Dimens√£o | Provider | Custo (USD/1M tokens) |
|--------|----------|----------|----------------------|
| `text-embedding-ada-002` | 1536 | OpenAI | $0.10 |
| `text-embedding-3-small` | 1536 | OpenAI | $0.02 |
| `text-embedding-3-large` | 3072 | OpenAI | $0.13 |
| Local (LM Studio/Ollama) | Vari√°vel | Local | Gr√°tis |

## üì° API Endpoints

### POST /vector/push

Envia chunks para o VectorDB com embeddings.

**Request:**
```json
{
  "doc_hashes": ["abc123...", "def456..."],
  "collection": "kb_regulatory",
  "overwrite": false,
  "batch_size": 64
}
```

**Par√¢metros:**
- `doc_hashes` (obrigat√≥rio) - Lista de hashes dos documentos
- `collection` - Nome da cole√ß√£o no Qdrant (default: `kb_regulatory`)
- `overwrite` - Se `true`, apaga pontos existentes antes (default: `false`)
- `batch_size` - Tamanho do lote para upsert (default: `64`)

**Response:**
```json
{
  "pushed": 128,
  "skipped": 0,
  "collection": "kb_regulatory"
}
```

### POST /vector/delete

Remove chunks do VectorDB.

**Request:**
```json
{
  "doc_hashes": ["abc123..."],
  "collection": "kb_regulatory"
}
```

**Response:**
```json
{
  "deleted": 64,
  "collection": "kb_regulatory"
}
```

## üéØ Fluxo Completo

### 1. Gerar/Aprovar Documentos

Via Agentic Search ou manualmente:
```bash
# Agentic Search
make agentic-html

# Resultado: documentos aprovados em search_result
```

### 2. Regenerar Chunks

```bash
curl -X POST http://localhost:8000/ingest/regenerate \
  -H "Content-Type: application/json" \
  -d '{
    "urls": ["https://www.gov.br/ans/.../rn-259.pdf"],
    "overwrite": true
  }'
```

**Resultado:**
- ‚úÖ Chunks salvos em `chunk_store`
- ‚úÖ Manifest atualizado (`status=done`, `chunk_count=15`)
- ‚úÖ `vector_status=none` (ainda n√£o enviado)

### 3. Push para VectorDB

```bash
curl -X POST http://localhost:8000/vector/push \
  -H "Content-Type: application/json" \
  -d '{
    "doc_hashes": ["abc123..."],
    "collection": "kb_regulatory",
    "overwrite": false
  }'
```

**O que acontece:**
1. ‚úÖ Busca chunks do `chunk_store`
2. ‚úÖ Gera embeddings (OpenAI/local)
3. ‚úÖ Cria points com ID determin√≠stico: `{doc_hash}:{chunk_id}`
4. ‚úÖ Upsert no Qdrant (idempotente)
5. ‚úÖ Atualiza manifest: `vector_status=present`, `last_pushed_at=NOW()`

**Resultado:**
```json
{
  "pushed": 15,
  "skipped": 0,
  "collection": "kb_regulatory"
}
```

### 4. Verificar Status

Via UI:
```
http://localhost:8000/ui
‚Üí Painel "‚úÖ Documentos Aprovados"
‚Üí Coluna "Vector" mostra badge verde "present"
```

## üé® Via Web UI

### Auto-Load ao abrir

A UI carrega automaticamente os √∫ltimos 100 aprovados ao abrir.

### A√ß√µes por Linha

**Rechunk:**
```
Clique "Rechunk" ‚Üí POST /ingest/regenerate
Status: none ‚Üí processing ‚Üí done
```

**Push:**
```
Clique "Push" ‚Üí POST /vector/push
Vector: none ‚Üí present
```

**Remove:**
```
Clique "Remove" ‚Üí POST /vector/delete
Vector: present ‚Üí none
```

### A√ß√µes em Lote

1. ‚òëÔ∏è Selecione documentos (checkboxes)
2. üéõÔ∏è Escolha a√ß√£o: `Push to Vector`
3. ‚öôÔ∏è Configure collection: `kb_regulatory`
4. ‚ñ∂Ô∏è Clique "Executar sele√ß√£o"
5. ‚úÖ Status atualiza automaticamente (polling 5s)

## üîç Chunking Strategy (Implementado)

### PDF
```
1. Extract text by page (pdfplumber)
2. LLM markers from first 2-3 pages (Art., Cap., Anexo)
   ‚Üí Prompt: "Sugira marcadores regex para segmentar este PDF regulat√≥rio"
3. Anchor-aware segmentation ‚Üí Token chunks
   ‚Üí Segments = split by markers
   ‚Üí Chunks = max 512 tokens, overlap 50
4. Metadata: page_hint, anchor_type, segment_index
```

### HTML
```
1. Readability extraction (trafilatura)
2. Regex anchor detection (H1-H3, Art., Anexo, Tabela)
3. Anchor-aware (if 3+ anchors) ‚Üí Token chunks
4. Fallback: token-only if few anchors
5. Metadata: source_type=html, num_anchors
```

### ZIP
```
(Not yet implemented - placeholder)
1. Extract nested files
2. Recursive processing for PDF/HTML
3. Table conversion for CSV/XLSX
```

## üéØ Por que Anchors ‚Üí Tokens?

‚úÖ **Structure-first** - Preserva unidades sem√¢nticas (Art. 5¬∫, Anexo II)  
‚úÖ **Citation-friendly** - Chunks alinhados com estrutura regulat√≥ria  
‚úÖ **Token-aware** - Max 512 tokens ‚Üí custos previs√≠veis  
‚úÖ **Overlap** - 50 tokens de sobreposi√ß√£o ‚Üí melhor contexto  
‚úÖ **Fallback robusto** - Sem anchors? Token chunking resolve  
‚úÖ **Page-aware (PDF)** - LLM s√≥ nas primeiras p√°ginas ‚Üí otimiza√ß√£o de custo

## üß™ Testando

### 1. Iniciar Qdrant Local

```bash
docker run -p 6333:6333 qdrant/qdrant
```

### 2. Testar Embeddings

```bash
python -c "
from embeddings.encoder import encode_texts
vecs = encode_texts(['teste'])
print(f'Dimension: {len(vecs[0])}')
"
```

### 3. Testar Push

```bash
# Via API
curl -X POST http://localhost:8000/vector/push \
  -H "Content-Type: application/json" \
  -d '{"doc_hashes":["abc123"], "collection":"test"}'

# Via UI
# 1. Abra http://localhost:8000/ui
# 2. Selecione documento
# 3. Clique "Push"
# 4. Monitore badge "Vector" ‚Üí none ‚Üí present
```

## üîê Idempot√™ncia

### Point ID Determin√≠stico

```python
point_id = f"{doc_hash}:{chunk_id}"
```

**Benef√≠cios:**
- ‚úÖ M√∫ltiplos pushes n√£o duplicam
- ‚úÖ Re-push atualiza embeddings/payload
- ‚úÖ Overwrite opcional para limpar antes

### Overwrite vs. Upsert

**Sem overwrite (default):**
```
Push 1: Insere 10 chunks
Push 2: Atualiza os mesmos 10 chunks (upsert)
Resultado: 10 pontos no Qdrant
```

**Com overwrite:**
```
Push 1: Insere 10 chunks
Regenerate: Gera 15 chunks novos
Push 2 (overwrite=true): Deleta 10, insere 15
Resultado: 15 pontos no Qdrant
```

## üö® Troubleshooting

### Erro: "Collection not found"

**Causa:** Collection n√£o existe no Qdrant

**Solu√ß√£o:** Autom√°tico! O c√≥digo cria a collection automaticamente:
```python
ensure_collection(client, "kb_regulatory", dim=1536)
```

### Erro: "Dimension mismatch"

**Causa:** `EMBED_DIM` n√£o bate com o modelo

**Solu√ß√£o:**
```bash
# Para text-embedding-3-small (1536)
EMBED_DIM=1536

# Para text-embedding-3-large (3072)
EMBED_DIM=3072
```

### Erro: "OpenAI API key not found"

**Causa:** `OPENAI_API_KEY` n√£o configurado

**Solu√ß√£o:**
```bash
# Adicione ao .env
OPENAI_API_KEY=sk-proj-...
```

### Chunks n√£o aparecem no Qdrant

**Debug:**
```bash
# 1. Verifique se chunks existem
curl "http://localhost:8000/chunks/status?doc_hashes=abc123"

# 2. Verifique logs do push
# Busque por: "push_start", "push_encode_failed", "push_upsert_failed"

# 3. Verifique Qdrant
curl "http://localhost:6333/collections/kb_regulatory"
```

## üìä Monitoramento

### Via UI (Real-time)

Badges atualizam a cada 5s:
- **Cache:** `none` ‚Üí `processing` ‚Üí `done`
- **Vector:** `none` ‚Üí `present`
- **Chunks:** Contador atualiza automaticamente

### Via API

```bash
# Status de manifests
curl "http://localhost:8000/chunks/status?doc_hashes=abc123,def456"

# Response
{
  "manifests": [
    {
      "doc_hash": "abc123",
      "status": "done",
      "chunk_count": 15,
      "vector_status": "present",
      "last_pushed_at": "2025-10-14T20:30:00Z",
      "last_pushed_collection": "kb_regulatory"
    }
  ]
}
```

## üéì Exemplos de Uso

### Fluxo Completo via CLI

```bash
# 1. Agentic Search (aprova documentos)
make agentic-html

# 2. Regenerar chunks dos aprovados
curl -X POST http://localhost:8000/ingest/regenerate \
  -H "Content-Type: application/json" \
  -d '{
    "urls": ["https://www.gov.br/ans/.../doc.pdf"],
    "overwrite": true
  }'

# 3. Push para VectorDB
curl -X POST http://localhost:8000/vector/push \
  -H "Content-Type: application/json" \
  -d '{
    "doc_hashes": ["abc123"],
    "collection": "kb_regulatory"
  }'

# 4. Verificar no Qdrant
curl "http://localhost:6333/collections/kb_regulatory/points/scroll" \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{"limit": 10, "with_payload": true}'
```

### Fluxo Completo via UI

```
1. Abra: http://localhost:8000/ui
2. Digite prompt: "Buscar RNs ANS sobre prazos"
3. Clique "üß† Gerar Plano"
4. Clique "üöÄ Executar"
5. Aguarde aprova√ß√µes (painel atualiza sozinho)
6. V√° em "‚úÖ Documentos Aprovados"
7. Selecione todos (‚òëÔ∏è)
8. Escolha "üîß Rechunk (overwrite)"
9. Clique "‚ñ∂Ô∏è Executar sele√ß√£o"
10. Aguarde chunks (badge Cache: done)
11. Escolha "‚¨ÜÔ∏è Push to Vector"
12. Clique "‚ñ∂Ô∏è Executar sele√ß√£o"
13. Aguarde (badge Vector: present) ‚úÖ
14. PRONTO! Chunks no VectorDB com embeddings
```

## üî¨ Arquitetura T√©cnica

### Point ID Format

```
{doc_hash}:{chunk_id}
```

**Exemplo:**
```
abc123def456...:0
abc123def456...:1
abc123def456...:2
```

**Vantagens:**
- ‚úÖ Determin√≠stico
- ‚úÖ Idempotente (m√∫ltiplos pushes n√£o duplicam)
- ‚úÖ Permite re-push parcial
- ‚úÖ Facilita delete por doc_hash

### Payload Structure

```json
{
  "doc_hash": "abc123...",
  "chunk_id": "0",
  "chunk_index": 0,
  "source_type": "pdf",
  "url": "https://...",
  "title": "RN 259",
  "text_len": 1024,
  "tokens": 256,
  "anchor_type": "artigo",
  "anchor_text": "Art. 5¬∫",
  "page_hint": 3,
  "pushed_at": "2025-10-14T20:30:00Z",
  "collection": "kb_regulatory"
}
```

### Embedding Generation

**OpenAI:**
```python
from openai import OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)
response = client.embeddings.create(
    model="text-embedding-3-small",
    input=["texto 1", "texto 2", ...]  # Batch support
)
embeddings = [item.embedding for item in response.data]
```

**Local (LM Studio/Ollama):**
```bash
# 1. Inicie LM Studio com modelo de embeddings
# 2. Configure:
OPENAI_BASE_URL=http://localhost:1234/v1
OPENAI_API_KEY=lm-studio  # qualquer valor
OPENAI_EMBEDDING_MODEL=nomic-embed-text  # ou outro
EMBED_DIM=768  # depende do modelo

# 3. API funciona igual (OpenAI-compatible)
```

## üìà Performance

### Batch Processing

- Default: 64 chunks por batch
- Embeddings gerados em batch (OpenAI suporta at√© 2048 por request)
- Upsert em batch para Qdrant

**Estimativa:**
- 1000 chunks (512 tokens cada) ~ 512k tokens
- text-embedding-3-small: $0.02/1M tokens = **$0.01**
- Tempo: ~5-10s (depende da rede)

### Recomenda√ß√µes

**Para grandes volumes:**
```json
{
  "batch_size": 128,  // Aumentar para mais throughput
  "collection": "kb_regulatory"
}
```

**Para re-push completo:**
```json
{
  "overwrite": true,  // Limpa antes
  "batch_size": 64
}
```

## üõ°Ô∏è Robustez

### Error Handling

**Encode failure:**
```
‚Üí Log: "push_encode_failed"
‚Üí Per-doc status: "encode_error"
‚Üí Skipped, n√£o para o push dos outros docs
```

**Upsert failure:**
```
‚Üí Log: "push_upsert_failed"
‚Üí Per-doc status: "upsert_error"
‚Üí Marca como "partial" se alguns batches ok
```

**Manifest update failure:**
```
‚Üí Log: "push_manifest_update_failed"
‚Üí Pontos J√Å est√£o no Qdrant
‚Üí Manifest n√£o atualizado (pode corrigir depois)
```

### Transa√ß√µes

- ‚ùå **N√£o** usa transa√ß√£o DB para push (opera√ß√£o externa)
- ‚úÖ **Idempotente** via point_id determin√≠stico
- ‚úÖ **Rollback seguro** no regenerate (transa√ß√£o DB)
- ‚úÖ **Retry manual** sempre poss√≠vel (re-push)

## üîó Integra√ß√£o com Agentic Search

### Workflow Autom√°tico

```python
# No /ingest/regenerate com push_after=true
{
  "urls": ["https://..."],
  "overwrite": true,
  "push_after": true,  # ‚Üê Push autom√°tico ap√≥s chunking
  "collection": "kb_regulatory"
}
```

**Resultado:**
1. ‚úÖ Regenera chunks
2. ‚úÖ Salva em chunk_store
3. ‚úÖ Gera embeddings
4. ‚úÖ Push para Qdrant
5. ‚úÖ Manifest: `vector_status=present`

### Audit Trail

Toda opera√ß√£o logada:
- `push_start` - In√≠cio do push
- `push_batch_done` - Cada batch upsert
- `push_manifest_updated` - Manifest atualizado
- `push_done` - Conclus√£o com totais

**Busca nos logs:**
```bash
cat logs/api.log | grep "push_" | jq .
```

## üéÅ Recursos Adicionais

### Filtros no Qdrant

Buscar por doc_hash:
```python
from qdrant_client.models import Filter, FieldCondition, MatchValue

filter_condition = Filter(
    must=[
        FieldCondition(
            key="doc_hash",
            match=MatchValue(value="abc123...")
        )
    ]
)

points = client.scroll(
    collection_name="kb_regulatory",
    scroll_filter=filter_condition,
    limit=100
)
```

### Buscar por Tipo

```python
filter_condition = Filter(
    must=[
        FieldCondition(
            key="source_type",
            match=MatchValue(value="pdf")
        )
    ]
)
```

### Buscar por Anchor

```python
filter_condition = Filter(
    must=[
        FieldCondition(
            key="anchor_type",
            match=MatchValue(value="artigo")
        )
    ]
)
```

## üìö Refer√™ncias

- [Qdrant Docs](https://qdrant.tech/documentation/)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [LM Studio](https://lmstudio.ai/)
- [Ollama](https://ollama.ai/)

---

**‚úÖ Sistema Completo End-to-End:**

```
Agentic Search ‚Üí Approve Docs ‚Üí Regenerate Chunks ‚Üí Push to Vector ‚Üí Query RAG
```

**üéâ PRONTO PARA PRODU√á√ÉO! üöÄ**

